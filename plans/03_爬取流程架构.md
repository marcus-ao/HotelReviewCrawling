# é£çŒªé…’åº—è¯„è®ºçˆ¬å–å®Œæ•´æµç¨‹æ¶æ„

## ä¸€ã€æ•´ä½“æ¶æ„è®¾è®¡

### 1.1 ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
    A[çˆ¬å–è°ƒåº¦å™¨] --> B[é…’åº—åˆ—è¡¨çˆ¬å–æ¨¡å—]
    A --> C[é…’åº—è¯¦æƒ…çˆ¬å–æ¨¡å—]
    A --> D[è¯„è®ºçˆ¬å–æ¨¡å—]
    
    B --> E[æ•°æ®æ¸…æ´—æ¨¡å—]
    C --> E
    D --> E
    
    E --> F[æ•°æ®å­˜å‚¨æ¨¡å—]
    F --> G[(PostgreSQLæ•°æ®åº“)]
    
    H[åçˆ¬è™«æ¨¡å—] -.-> B
    H -.-> C
    H -.-> D
    
    I[ç›‘æ§å‘Šè­¦æ¨¡å—] -.-> A
    I -.-> B
    I -.-> C
    I -.-> D
    
    J[DrissionPageæµè§ˆå™¨æ§åˆ¶] --> B
    J --> C
    J --> D
```

### 1.2 æŠ€æœ¯æ ˆé€‰å‹

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **çˆ¬è™«æ¡†æ¶** | DrissionPage | åŸºäºCDPåè®®ï¼Œç»•è¿‡webdriveræ£€æµ‹ |
| **æµè§ˆå™¨** | Chrome (Debugæ¨¡å¼) | æ‰‹åŠ¨ç™»å½•åæ¥ç®¡ |
| **æ•°æ®åº“** | PostgreSQL + pgvector | æ”¯æŒå‘é‡æ£€ç´¢ |
| **ORM** | SQLAlchemy | Python ORMæ¡†æ¶ |
| **ä»»åŠ¡è°ƒåº¦** | APScheduler | å®šæ—¶ä»»åŠ¡è°ƒåº¦ |
| **æ—¥å¿—** | Loguru | ç®€æ´çš„æ—¥å¿—åº“ |
| **é…ç½®ç®¡ç†** | Python-dotenv | ç¯å¢ƒå˜é‡ç®¡ç† |
| **æ•°æ®éªŒè¯** | Pydantic | æ•°æ®æ¨¡å‹éªŒè¯ |
| **å¹¶å‘æ§åˆ¶** | asyncio + aiohttp | å¼‚æ­¥IO |

## äºŒã€çˆ¬å–æµç¨‹è®¾è®¡

### 2.1 é˜¶æ®µä¸€ï¼šé…’åº—å€™é€‰é›†æ„å»º

#### æµç¨‹å›¾

```mermaid
flowchart TD
    Start[å¼€å§‹] --> Init[åˆå§‹åŒ–çˆ¬è™«é…ç½®]
    Init --> LoadRegions[åŠ è½½å¹¿å·6å¤§åŠŸèƒ½åŒºé…ç½®]
    
    LoadRegions --> LoopRegion{éå†æ¯ä¸ªåŠŸèƒ½åŒº}
    LoopRegion -->|ä¸‹ä¸€ä¸ªåŠŸèƒ½åŒº| SelectBusinessZone[é€‰æ‹©3ä¸ªä»£è¡¨æ€§å•†åœˆ]
    
    SelectBusinessZone --> LoopZone{éå†æ¯ä¸ªå•†åœˆ}
    LoopZone -->|ä¸‹ä¸€ä¸ªå•†åœˆ| PriceLoop[æ‰§è¡Œ4æ¬¡ä»·æ ¼åˆ†å±‚æœç´¢]
    
    PriceLoop --> Search1[æœç´¢ç»æµå‹0-300å…ƒ Top4]
    Search1 --> Search2[æœç´¢èˆ’é€‚å‹300-600å…ƒ Top6]
    Search2 --> Search3[æœç´¢é«˜æ¡£å‹600-1200å…ƒ Top3]
    Search3 --> Search4[æœç´¢å¥¢åå‹1200å…ƒ+ Top2]
    
    Search4 --> ExtractHotel[æå–é…’åº—åŸºæœ¬ä¿¡æ¯]
    ExtractHotel --> SaveHotel[ä¿å­˜åˆ°hotelè¡¨]
    
    SaveHotel --> CheckZone{å•†åœˆæ˜¯å¦éå†å®Œ?}
    CheckZone -->|å¦| LoopZone
    CheckZone -->|æ˜¯| CheckRegion{åŠŸèƒ½åŒºæ˜¯å¦éå†å®Œ?}
    
    CheckRegion -->|å¦| LoopRegion
    CheckRegion -->|æ˜¯| Summary[ç”Ÿæˆé…’åº—å€™é€‰é›†ç»Ÿè®¡]
    Summary --> End[ç»“æŸ]
```

#### å®ç°ç»†èŠ‚

**1. åŒºåŸŸé…ç½®æ•°æ®ç»“æ„**

```python
GUANGZHOU_REGIONS = {
    "CBDå•†åŠ¡åŒº": {
        "business_zones": [
            {"name": "ç æ±Ÿæ–°åŸ/äº”ç¾Šæ–°åŸå•†åœˆ", "code": "39584"},
            {"name": "ç«è½¦ä¸œç«™/å¤©æ²³ä½“è‚²ä¸­å¿ƒå•†åœˆ", "code": "39585"},
            {"name": "å¤©æ²³å…¬å›­/ä¸œåœƒå•†åœˆ", "code": "39586"}
        ],
        "price_ranges": [
            {"level": "R2", "min": 100, "max": 300, "top_n": 4, "sort": "rating"},
            {"level": "R3", "min": 300, "max": 600, "top_n": 6, "sort": "sales"},
            {"level": "R4", "min": 600, "max": 1200, "top_n": 3, "sort": "sales"},
            {"level": "R5", "min": 1200, "max": 9999, "top_n": 2, "sort": "comprehensive"}
        ]
    },
    "è€åŸæ–‡åŒ–åŒº": {
        # ... ç±»ä¼¼ç»“æ„
    },
    # ... å…¶ä»–åŠŸèƒ½åŒº
}
```

**2. æœç´¢URLæ„é€ **

```python
def build_search_url(city_code, business_zone, price_level, check_in, check_out, page=1):
    """
    æ„é€ æœç´¢URL
    
    ç¤ºä¾‹URL:
    https://hotel.fliggy.com/hotel_list3.htm?
        city=440100&
        keywords=&
        checkIn=2026-01-26&
        checkOut=2026-01-27&
        location=39584&  # å•†åœˆä»£ç 
        jgR3&  # ä»·æ ¼æ¡£æ¬¡
        pg=1  # é¡µç 
    """
    base_url = "https://hotel.fliggy.com/hotel_list3.htm"
    params = {
        "city": city_code,
        "checkIn": check_in,
        "checkOut": check_out,
        "location": business_zone,
        f"jg{price_level}": "",
        "pg": page
    }
    return f"{base_url}?{'&'.join(f'{k}={v}' for k, v in params.items())}"
```

**3. é…’åº—ä¿¡æ¯æå–**

ç”±äºHTMLä¸­é…’åº—åˆ—è¡¨æ˜¯åŠ¨æ€åŠ è½½çš„ï¼Œéœ€è¦ï¼š
- ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
- æå–JavaScriptä¸­çš„æ•°æ®ï¼ˆå¯èƒ½åœ¨`window.__INITIAL_STATE__`æˆ–ç±»ä¼¼å˜é‡ä¸­ï¼‰
- æˆ–è€…é€šè¿‡æŠ“åŒ…åˆ†æAJAXæ¥å£

```python
async def extract_hotel_list(page):
    """
    ä»é¡µé¢æå–é…’åº—åˆ—è¡¨
    
    å¯èƒ½çš„æ•°æ®æ¥æºï¼š
    1. JavaScriptå˜é‡ä¸­çš„JSONæ•°æ®
    2. AJAXæ¥å£è¿”å›çš„æ•°æ®
    """
    # æ–¹æ¡ˆ1ï¼šä»JavaScriptå˜é‡æå–
    hotel_data = page.run_js("return window.__INITIAL_STATE__.hotelList")
    
    # æ–¹æ¡ˆ2ï¼šç­‰å¾…å…ƒç´ åŠ è½½åæå–
    # hotels = page.eles('.hotel-item')
    
    return parse_hotel_data(hotel_data)
```

### 2.2 é˜¶æ®µäºŒï¼šè¯„è®ºè¯¦æƒ…é‡‡é›†

#### æµç¨‹å›¾

```mermaid
flowchart TD
    Start[å¼€å§‹] --> LoadHotels[åŠ è½½å¾…çˆ¬å–é…’åº—åˆ—è¡¨]
    LoadHotels --> LoopHotel{éå†æ¯å®¶é…’åº—}
    
    LoopHotel -->|ä¸‹ä¸€å®¶é…’åº—| CheckTotal[æ£€æŸ¥æ€»è¯„è®ºæ•°]
    CheckTotal -->|<50æ¡| Skip[è·³è¿‡è¯¥é…’åº—]
    CheckTotal -->|>=50æ¡| InitQuota[åˆå§‹åŒ–é…é¢: Max 300æ¡]
    
    InitQuota --> Phase1[é˜¶æ®µ1: è´Ÿé¢è­¦ç¤ºæ± ]
    Phase1 --> Filter1[ç­›é€‰: å·®è¯„1-2åˆ†+ä¸­è¯„3åˆ†]
    Filter1 --> Sort1[æ’åº: æŒ‰æ—¶é—´æœ€æ–°]
    Sort1 --> Crawl1[çˆ¬å–: ä¸Šé™100æ¡]
    Crawl1 --> Dedup1[å»é‡: è®°å½•review_id]
    
    Dedup1 --> Phase2[é˜¶æ®µ2: é«˜è´¨é‡è¯æ®æ± ]
    Phase2 --> Filter2[ç­›é€‰: æœ‰å›¾/è§†é¢‘]
    Filter2 --> Sort2[æ’åº: æŒ‰æ—¶é—´æœ€æ–°]
    Sort2 --> Crawl2[çˆ¬å–: ä¸Šé™150æ¡]
    Crawl2 --> Dedup2[å»é‡: æ£€æŸ¥review_id]
    
    Dedup2 --> CheckQuota{æ˜¯å¦è¾¾åˆ°300æ¡?}
    CheckQuota -->|æ˜¯| SaveReviews[ä¿å­˜è¯„è®ºæ•°æ®]
    CheckQuota -->|å¦| Phase3[é˜¶æ®µ3: æ—¶æ•ˆæ€§è¡¥å…¨æ± ]
    
    Phase3 --> Filter3[ç­›é€‰: å…¨éƒ¨è¯„è®º]
    Filter3 --> Sort3[æ’åº: æŒ‰æ—¶é—´æœ€æ–°]
    Sort3 --> Crawl3[çˆ¬å–: å¡«æ»¡å‰©ä½™é…é¢]
    Crawl3 --> Dedup3[å»é‡: æ£€æŸ¥review_id]
    
    Dedup3 --> SaveReviews
    SaveReviews --> ExtractDetails[æå–è¯„è®ºè¯¦ç»†ä¿¡æ¯]
    ExtractDetails --> SaveDB[ä¿å­˜åˆ°æ•°æ®åº“]
    
    SaveDB --> CheckHotel{é…’åº—æ˜¯å¦éå†å®Œ?}
    CheckHotel -->|å¦| LoopHotel
    CheckHotel -->|æ˜¯| Summary[ç”Ÿæˆçˆ¬å–ç»Ÿè®¡æŠ¥å‘Š]
    
    Skip --> CheckHotel
    Summary --> End[ç»“æŸ]
```

#### å®ç°ç»†èŠ‚

**1. è¯„è®ºç­›é€‰å‚æ•°**

```python
REVIEW_FILTERS = {
    "negative_pool": {
        "rate_score": 2,  # å·®è¯„+ä¸­è¯„
        "sort": "time",  # æŒ‰æ—¶é—´æ’åº
        "max_count": 100,
        "priority": 1
    },
    "evidence_pool": {
        "rate_score": 3,  # æœ‰å›¾
        "sort": "time",
        "max_count": 150,
        "priority": 2
    },
    "latest_pool": {
        "rate_score": 0,  # å…¨éƒ¨
        "sort": "time",
        "max_count": None,  # å¡«æ»¡å‰©ä½™é…é¢
        "priority": 3
    }
}
```

**2. è¯„è®ºURLæ„é€ **

```python
def build_review_url(hotel_id, rate_score, page=1):
    """
    æ„é€ è¯„è®ºåˆ—è¡¨URLï¼ˆå¯èƒ½æ˜¯AJAXæ¥å£ï¼‰
    
    é¢„ä¼°æ¥å£æ ¼å¼:
    https://hotel.fliggy.com/ajax/getReviews.do?
        hid=3472&
        rateScore=2&  # 0-å…¨éƒ¨, 1-å¥½è¯„, 2-å·®è¯„, 3-æœ‰å›¾
        page=1&
        pageSize=20
    """
    return f"https://hotel.fliggy.com/ajax/getReviews.do?hid={hotel_id}&rateScore={rate_score}&page={page}"
```

**3. è¯„è®ºæ•°æ®æå–**

```python
def extract_review_data(review_element):
    """
    ä»HTMLå…ƒç´ æå–è¯„è®ºæ•°æ®
    """
    return {
        "review_id": extract_review_id(review_element),
        "user_name": review_element.ele('.tb-r-buyer').text,
        "content": review_element.ele('.tb-r-cnt').text,
        "comment_tags": review_element.ele('.comment-name').text,
        "create_time": parse_time(review_element.ele('.tb-r-date').text),
        "score_clean": extract_star_score(review_element, "æ¸…æ´ç¨‹åº¦"),
        "score_service": extract_star_score(review_element, "æœåŠ¡ä½“éªŒ"),
        "score_value": extract_star_score(review_element, "æ€§ä»·æ¯”"),
        "has_images": bool(review_element.eles('.tb-r-photos')),
        "image_urls": extract_image_urls(review_element),
        "reply_content": extract_reply(review_element),
        "reply_time": extract_reply_time(review_element)
    }

def extract_star_score(element, score_type):
    """
    ä»æ˜Ÿçº§è¯„åˆ†ä¸­æå–åˆ†æ•°
    
    HTMLç»“æ„:
    <span class="stars">â˜…â˜…â˜…â˜…â˜…<em style="width:100%">â˜…â˜…â˜…â˜…â˜…</em></span>
    
    width:100% = 5æ˜Ÿ
    width:80% = 4æ˜Ÿ
    width:60% = 3æ˜Ÿ
    width:40% = 2æ˜Ÿ
    width:20% = 1æ˜Ÿ
    """
    score_element = element.ele(f'li:contains("{score_type}") .stars em')
    if score_element:
        width_str = score_element.attr('style')
        # æå–widthå€¼ï¼Œå¦‚ "width:100%" -> 100
        width = int(width_str.split(':')[1].replace('%', '').strip())
        return round(width / 20)  # è½¬æ¢ä¸º1-5æ˜Ÿ
    return None
```

### 2.3 é˜¶æ®µä¸‰ï¼šæ•°æ®æ¸…æ´—ä¸å­˜å‚¨

#### æµç¨‹å›¾

```mermaid
flowchart TD
    Start[æ¥æ”¶åŸå§‹æ•°æ®] --> Validate[æ•°æ®éªŒè¯]
    Validate -->|éªŒè¯å¤±è´¥| Log[è®°å½•é”™è¯¯æ—¥å¿—]
    Validate -->|éªŒè¯æˆåŠŸ| Clean[æ•°æ®æ¸…æ´—]
    
    Clean --> RemoveHTML[å»é™¤HTMLæ ‡ç­¾]
    RemoveHTML --> RemoveEmoji[å¤„ç†è¡¨æƒ…ç¬¦å·]
    RemoveEmoji --> Normalize[æ–‡æœ¬è§„èŒƒåŒ–]
    
    Normalize --> CheckDup[æ£€æŸ¥é‡å¤]
    CheckDup -->|é‡å¤| Skip[è·³è¿‡]
    CheckDup -->|ä¸é‡å¤| Transform[æ•°æ®è½¬æ¢]
    
    Transform --> CalcFields[è®¡ç®—è¡ç”Ÿå­—æ®µ]
    CalcFields --> SaveDB[(ä¿å­˜åˆ°æ•°æ®åº“)]
    
    SaveDB --> UpdateStats[æ›´æ–°ç»Ÿè®¡ä¿¡æ¯]
    UpdateStats --> End[å®Œæˆ]
    
    Log --> End
    Skip --> End
```

#### å®ç°ç»†èŠ‚

**1. æ•°æ®éªŒè¯æ¨¡å‹ï¼ˆPydanticï¼‰**

```python
from pydantic import BaseModel, validator
from datetime import datetime
from typing import Optional, List

class ReviewModel(BaseModel):
    review_id: int
    hotel_id: int
    user_name: str
    content: str
    comment_tags: Optional[str]
    create_time: datetime
    score_clean: Optional[int]
    score_service: Optional[int]
    score_value: Optional[int]
    has_images: bool = False
    image_urls: List[str] = []
    reply_content: Optional[str]
    reply_time: Optional[datetime]
    
    @validator('content')
    def content_not_empty(cls, v):
        if not v or len(v.strip()) < 10:
            raise ValueError('è¯„è®ºå†…å®¹è¿‡çŸ­')
        return v.strip()
    
    @validator('score_clean', 'score_service', 'score_value')
    def score_range(cls, v):
        if v is not None and (v < 1 or v > 5):
            raise ValueError('è¯„åˆ†å¿…é¡»åœ¨1-5ä¹‹é—´')
        return v
    
    @property
    def score_avg(self):
        scores = [s for s in [self.score_clean, self.score_service, self.score_value] if s is not None]
        return round(sum(scores) / len(scores), 1) if scores else None
    
    @property
    def content_length(self):
        return len(self.content)
```

**2. æ•°æ®æ¸…æ´—å‡½æ•°**

```python
import re
from html import unescape

def clean_text(text: str) -> str:
    """
    æ¸…æ´—æ–‡æœ¬å†…å®¹
    """
    if not text:
        return ""
    
    # 1. HTMLå®ä½“è§£ç 
    text = unescape(text)
    
    # 2. å»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)
    
    # 3. å¤„ç†è¡¨æƒ…ç¬¦å·ï¼ˆä¿ç•™æˆ–è½¬æ¢ï¼‰
    # é€‰é¡¹1: ä¿ç•™è¡¨æƒ…
    # é€‰é¡¹2: ç§»é™¤è¡¨æƒ…
    # text = re.sub(r'[\U00010000-\U0010ffff]', '', text)
    
    # 4. è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    
    # 5. å»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    
    return text

def extract_tags_from_comment_name(comment_name: str) -> List[str]:
    """
    ä»comment-nameä¸­æå–æ ‡ç­¾
    
    è¾“å…¥: "#æœåŠ¡çƒ­å¿ƒ,#åœè½¦æ–¹ä¾¿ ğŸ›åºŠ"
    è¾“å‡º: ["æœåŠ¡çƒ­å¿ƒ", "åœè½¦æ–¹ä¾¿", "åºŠ"]
    """
    if not comment_name:
        return []
    
    # æå–#æ ‡ç­¾
    tags = re.findall(r'#([^#,ï¼Œ\s]+)', comment_name)
    
    # æå–emojiåçš„æ–‡å­—
    emoji_tags = re.findall(r'[\U00010000-\U0010ffff]\s*([^\s,ï¼Œ]+)', comment_name)
    
    return list(set(tags + emoji_tags))
```

## ä¸‰ã€åçˆ¬è™«ç­–ç•¥

### 3.1 æ ¸å¿ƒç­–ç•¥

| ç­–ç•¥ | å®ç°æ–¹å¼ | è¯´æ˜ |
|------|---------|------|
| **æµè§ˆå™¨æ¥ç®¡** | DrissionPage + Chrome Debugæ¨¡å¼ | æ‰‹åŠ¨ç™»å½•åæ¥ç®¡ï¼Œç»§æ‰¿Cookie |
| **éšæœºå»¶è¿Ÿ** | random.uniform(3, 6)ç§’ | æ¨¡æ‹Ÿäººç±»é˜…è¯»æ—¶é—´ |
| **User-Agentè½®æ¢** | éšæœºé€‰æ‹©å¸¸è§UA | é¿å…å•ä¸€UAè¢«è¯†åˆ« |
| **ä»£ç†IPæ± ** | å¯é€‰ï¼ŒæŒ‰éœ€é…ç½® | é«˜é¢‘çˆ¬å–æ—¶ä½¿ç”¨ |
| **æ»‘å—éªŒè¯å¤„ç†** | è‡ªåŠ¨å°è¯• + äººå·¥å…œåº• | æ£€æµ‹åˆ°æ»‘å—æ—¶æš‚åœç­‰å¾…äººå·¥ |
| **è¯·æ±‚é¢‘ç‡æ§åˆ¶** | ä»¤ç‰Œæ¡¶ç®—æ³• | æ§åˆ¶æ¯åˆ†é’Ÿè¯·æ±‚æ•° |
| **ä¼šè¯ä¿æŒ** | å¤ç”¨åŒä¸€æµè§ˆå™¨å®ä¾‹ | ä¿æŒç™»å½•çŠ¶æ€ |

### 3.2 å®ç°ä»£ç 

```python
from DrissionPage import ChromiumPage
import random
import time
from typing import Optional

class AntiCrawler:
    def __init__(self):
        self.page: Optional[ChromiumPage] = None
        self.last_request_time = 0
        self.min_interval = 3  # æœ€å°é—´éš”3ç§’
        self.max_interval = 6  # æœ€å¤§é—´éš”6ç§’
        
    def init_browser(self, debug_port=9222):
        """
        åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆæ¥ç®¡å·²ç™»å½•çš„Chromeï¼‰
        """
        self.page = ChromiumPage(addr_or_opts=f'127.0.0.1:{debug_port}')
        return self.page
    
    def random_delay(self):
        """
        éšæœºå»¶è¿Ÿ
        """
        delay = random.uniform(self.min_interval, self.max_interval)
        time.sleep(delay)
    
    def check_and_handle_captcha(self):
        """
        æ£€æŸ¥å¹¶å¤„ç†éªŒè¯ç 
        """
        # æ£€æµ‹æ»‘å—éªŒè¯ç 
        captcha = self.page.ele('#nc_1_n1z', timeout=2)
        if captcha:
            print("æ£€æµ‹åˆ°æ»‘å—éªŒè¯ç ï¼Œå°è¯•è‡ªåŠ¨å¤„ç†...")
            try:
                # å°è¯•è‡ªåŠ¨æ‹–æ‹½
                self.auto_slide_captcha(captcha)
                time.sleep(2)
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                if self.page.ele('#nc_1_n1z', timeout=1):
                    print("è‡ªåŠ¨å¤„ç†å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯...")
                    input("å®ŒæˆéªŒè¯åæŒ‰Enterç»§ç»­...")
            except Exception as e:
                print(f"è‡ªåŠ¨å¤„ç†éªŒè¯ç å¤±è´¥: {e}")
                input("è¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯åæŒ‰Enterç»§ç»­...")
    
    def auto_slide_captcha(self, captcha_element):
        """
        è‡ªåŠ¨æ‹–æ‹½æ»‘å—ï¼ˆç®€å•å®ç°ï¼‰
        """
        # è·å–æ»‘å—ä½ç½®
        rect = captcha_element.rect
        
        # æ¨¡æ‹Ÿäººç±»æ‹–æ‹½ï¼šåˆ†æ®µç§»åŠ¨
        total_distance = 300  # é¢„ä¼°è·ç¦»
        steps = random.randint(15, 25)
        
        for i in range(steps):
            distance = total_distance / steps
            captcha_element.drag(distance, 0, duration=random.uniform(0.1, 0.3))
            time.sleep(random.uniform(0.01, 0.05))
```

### 3.3 é”™è¯¯å¤„ç†ä¸é‡è¯•

```python
from tenacity import retry, stop_after_attempt, wait_exponential

class CrawlerWithRetry:
    @retry(
        stop=stop_after_attempt(3),  # æœ€å¤šé‡è¯•3æ¬¡
        wait=wait_exponential(multiplier=1, min=4, max=10)  # æŒ‡æ•°é€€é¿
    )
    def fetch_with_retry(self, url):
        """
        å¸¦é‡è¯•çš„è¯·æ±‚
        """
        try:
            self.anti_crawler.random_delay()
            self.page.get(url)
            self.anti_crawler.check_and_handle_captcha()
            return self.page.html
        except Exception as e:
            print(f"è¯·æ±‚å¤±è´¥: {e}")
            raise
```

## å››ã€ç›‘æ§ä¸æ—¥å¿—

### 4.1 æ—¥å¿—é…ç½®

```python
from loguru import logger
import sys

# é…ç½®æ—¥å¿—
logger.remove()  # ç§»é™¤é»˜è®¤handler

# æ§åˆ¶å°è¾“å‡º
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="INFO"
)

# æ–‡ä»¶è¾“å‡º
logger.add(
    "logs/crawler_{time:YYYY-MM-DD}.log",
    rotation="00:00",  # æ¯å¤©è½®è½¬
    retention="30 days",  # ä¿ç•™30å¤©
    compression="zip",  # å‹ç¼©
    level="DEBUG"
)

# é”™è¯¯æ—¥å¿—å•ç‹¬è®°å½•
logger.add(
    "logs/error_{time:YYYY-MM-DD}.log",
    rotation="00:00",
    retention="90 days",
    level="ERROR"
)
```

### 4.2 è¿›åº¦ç›‘æ§

```python
from tqdm import tqdm

class ProgressMonitor:
    def __init__(self, total_hotels):
        self.total_hotels = total_hotels
        self.completed_hotels = 0
        self.total_reviews = 0
        self.failed_hotels = []
        
        self.pbar = tqdm(total=total_hotels, desc="çˆ¬å–è¿›åº¦")
    
    def update_hotel(self, hotel_id, review_count, success=True):
        """
        æ›´æ–°é…’åº—çˆ¬å–è¿›åº¦
        """
        self.completed_hotels += 1
        self.total_reviews += review_count
        
        if not success:
            self.failed_hotels.append(hotel_id)
        
        self.pbar.update(1)
        self.pbar.set_postfix({
            "è¯„è®ºæ•°": self.total_reviews,
            "å¤±è´¥æ•°": len(self.failed_hotels)
        })
    
    def get_summary(self):
        """
        è·å–çˆ¬å–æ‘˜è¦
        """
        return {
            "total_hotels": self.total_hotels,
            "completed_hotels": self.completed_hotels,
            "total_reviews": self.total_reviews,
            "failed_hotels": len(self.failed_hotels),
            "success_rate": f"{(self.completed_hotels - len(self.failed_hotels)) / self.total_hotels * 100:.2f}%"
        }
```

## äº”ã€é¡¹ç›®ç›®å½•ç»“æ„

```
HotelReviewCrawler/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py          # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ regions.py           # åŒºåŸŸé…ç½®
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hotel_list.py        # é…’åº—åˆ—è¡¨çˆ¬è™«
â”‚   â”œâ”€â”€ hotel_detail.py      # é…’åº—è¯¦æƒ…çˆ¬è™«
â”‚   â”œâ”€â”€ review.py            # è¯„è®ºçˆ¬è™«
â”‚   â””â”€â”€ anti_crawler.py      # åçˆ¬è™«æ¨¡å—
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py            # ORMæ¨¡å‹
â”‚   â”œâ”€â”€ connection.py        # æ•°æ®åº“è¿æ¥
â”‚   â””â”€â”€ init_db.sql          # åˆå§‹åŒ–SQL
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cleaner.py           # æ•°æ®æ¸…æ´—
â”‚   â”œâ”€â”€ validator.py         # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ logger.py            # æ—¥å¿—é…ç½®
â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ task_scheduler.py    # ä»»åŠ¡è°ƒåº¦
â”œâ”€â”€ logs/                    # æ—¥å¿—ç›®å½•
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
â”œâ”€â”€ main.py                  # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt         # ä¾èµ–åŒ…
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜
```

## å…­ã€æ‰§è¡Œè®¡åˆ’

### 6.1 æ—¶é—´å®‰æ’

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |
|------|------|---------|
| **å‡†å¤‡é˜¶æ®µ** | ç¯å¢ƒæ­å»ºã€æ•°æ®åº“åˆå§‹åŒ– | 0.5å¤© |
| **å¼€å‘é˜¶æ®µ** | ç¼–å†™çˆ¬è™«ä»£ç  | 2å¤© |
| **æµ‹è¯•é˜¶æ®µ** | å°è§„æ¨¡æµ‹è¯•ã€è°ƒè¯• | 1å¤© |
| **çˆ¬å–é˜¶æ®µ** | æ­£å¼çˆ¬å–æ•°æ® | 2-3å¤© |
| **éªŒè¯é˜¶æ®µ** | æ•°æ®è´¨é‡æ£€æŸ¥ | 0.5å¤© |

### 6.2 é£é™©æ§åˆ¶

| é£é™© | åº”å¯¹æªæ–½ |
|------|---------|
| **è´¦å·è¢«å°** | å‡†å¤‡å¤šä¸ªè´¦å·è½®æ¢ |
| **IPè¢«å°** | ä½¿ç”¨ä»£ç†IPæ±  |
| **éªŒè¯ç é¢‘ç¹** | é™ä½çˆ¬å–é¢‘ç‡ï¼Œå¢åŠ äººå·¥ä»‹å…¥ |
| **æ•°æ®ä¸¢å¤±** | å®æ—¶å¤‡ä»½ï¼Œæ–­ç‚¹ç»­çˆ¬ |
| **ç½‘ç»œä¸ç¨³å®š** | å®ç°é‡è¯•æœºåˆ¶ |

## ä¸ƒã€ä¸‹ä¸€æ­¥å·¥ä½œ

1. âœ… å®Œæˆçˆ¬å–æµç¨‹æ¶æ„è®¾è®¡
2. â­ï¸ ç¼–å†™å…·ä½“çš„çˆ¬è™«ä»£ç 
3. â­ï¸ å®ç°æ•°æ®åº“ORMæ¨¡å‹
4. â­ï¸ å¼€å‘ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ
5. â­ï¸ è¿›è¡Œå°è§„æ¨¡æµ‹è¯•
